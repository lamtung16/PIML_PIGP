{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cvxpy as cp\n",
    "import math\n",
    "import numpy as np\n",
    "import scipy\n",
    "import scipy.stats\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.linalg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HmcSampler:\n",
    "    min_t = 0.00001\n",
    "\n",
    "    def __init__(self, dim, init, f, g, verbose):\n",
    "        \"\"\"\n",
    "\n",
    "        :param dim:  dimension\n",
    "        :param init: (dim, ), the initial value for HMC\n",
    "        :param f:    (q, dim), coefficient for linear constraints\n",
    "        :param g:    (q,), linear constraints: f*X+g >= 0\n",
    "        \"\"\"\n",
    "        self.dim = dim\n",
    "        self.lastSample = init\n",
    "        self.f = f\n",
    "        self.g = g\n",
    "        self.verbose = verbose\n",
    "\n",
    "    def getNextLinearHitTime(self, a, b):\n",
    "        \"\"\"\n",
    "        the position x(t) = a * sin(t) + b * cos(t)\n",
    "\n",
    "        :param a: (dim, ) initial value for a (initial velocity)\n",
    "        :param b: (dim, ) initial value for b (initial position)\n",
    "        :return: hit_time: the time for the hit\n",
    "                 cn : the cn-th constraint is active at hit time.\n",
    "        \"\"\"\n",
    "        hit_time = 0\n",
    "        cn = 0\n",
    "\n",
    "        if self.f is None:\n",
    "            return hit_time, cn\n",
    "\n",
    "        f = self.f\n",
    "        g = self.g\n",
    "        for i in range(f.shape[0]):\n",
    "            # constraints: f[i].dot(x)+g[i] >= 0\n",
    "            fa = f[i].dot(a)\n",
    "            fb = f[i].dot(b)\n",
    "            u = np.sqrt(fa*fa + fb*fb)\n",
    "            # if u > g[i] and u > -g[i]:\n",
    "            if -u < g[i] < u:\n",
    "                # otherwise the constrain will always be satisfied\n",
    "                phi = np.arctan2(-fa, fb)  # -pi < phi < pi\n",
    "                t1 = np.arccos(-g[i]/u) - phi  # -pi < t1 < 2*pi\n",
    "\n",
    "                if t1 < 0:\n",
    "                    t1 += 2 * np.pi  # 0 < t1 < 2*pi\n",
    "                if np.abs(t1) < self.min_t or \\\n",
    "                   np.abs(t1-2*np.pi) < self.min_t:\n",
    "                    t1 = 0\n",
    "\n",
    "                t2 = -t1 - 2*phi  # -4*pi < t2 < 2*pi\n",
    "                if t2 < 0:\n",
    "                    t2 += 2*np.pi  # -2*pi < t2 < 2*pi\n",
    "                if t2 < 0:\n",
    "                    t2 += 2*np.pi  # 0 < t2 < 2*pi\n",
    "\n",
    "                if np.abs(t2) < self.min_t or \\\n",
    "                   np.abs(t2 - 2*np.pi) < self.min_t:\n",
    "                    t2 = 0\n",
    "\n",
    "                if t1 == 0:\n",
    "                    t = t2\n",
    "                elif t2 == 0:\n",
    "                    t = t1\n",
    "                else:\n",
    "                    t = np.minimum(t1, t2)\n",
    "\n",
    "                if self.min_t < t and (hit_time == 0 or t < hit_time):\n",
    "                    hit_time = t\n",
    "                    cn = i\n",
    "        return hit_time, cn\n",
    "\n",
    "    def verifyConstraints(self, b):\n",
    "        \"\"\"\n",
    "\n",
    "        :param b:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        if self.f is not None:\n",
    "            return np.min(self.f@b + self.g)\n",
    "        else:\n",
    "            return 1\n",
    "\n",
    "    def sampleNext(self):\n",
    "        T = np.pi / 2  # how much time to move\n",
    "        b = self.lastSample\n",
    "        dim = self.dim\n",
    "\n",
    "        count_sample_vel = 0\n",
    "\n",
    "        while True:\n",
    "            velsign = 0\n",
    "            # sample new initial velocity\n",
    "            a = np.random.normal(0, 1, dim)\n",
    "\n",
    "            count_sample_vel += 1\n",
    "            if self.verbose and count_sample_vel % 50 == 0:\n",
    "                print(\"Has sampled %d times of initial velocity.\" % count_sample_vel)\n",
    "\n",
    "            tt = T  # the time left to move\n",
    "            while True:\n",
    "                t, c1 = self.getNextLinearHitTime(a, b)\n",
    "                # t: how much time to move to hit the boundary, if t == 0, move tt\n",
    "                # c1: the strict constraint at hit time\n",
    "\n",
    "                if t == 0 or tt < t:\n",
    "                    # if no wall to be hit (t == 0) or not enough\n",
    "                    # time left to hit the wall (tt < t)\n",
    "                    break\n",
    "\n",
    "                tt -= t  # time left to move after hitting the wall\n",
    "                new_b = np.sin(t) * a + np.cos(t) * b  # hit location\n",
    "                hit_vel = np.cos(t) * a - np.sin(t) * b  # hit velocity\n",
    "                b = new_b\n",
    "                # reflect the velocity and verify that it points in the right direction\n",
    "                f2 = np.dot(self.f[c1], self.f[c1])\n",
    "                alpha = np.dot(self.f[c1], hit_vel) / f2\n",
    "                a = hit_vel - 2*alpha*self.f[c1]  # reflected velocity\n",
    "\n",
    "                velsign = a.dot(self.f[c1])\n",
    "\n",
    "                if velsign < 0:\n",
    "                    # get out of inner while, resample the velocity and start again\n",
    "                    # this occurs rarelly, due to numerical instabilities\n",
    "                    break\n",
    "\n",
    "            if velsign < 0:\n",
    "                # go to the beginning of outer while\n",
    "                continue\n",
    "\n",
    "            bb = np.sin(tt) * a + np.cos(tt) * b\n",
    "            check = self.verifyConstraints(bb)\n",
    "            if check >= 0:\n",
    "                # verify that we don't violate the constraints\n",
    "                # due to a numerical instability\n",
    "                if self.verbose:\n",
    "                    print(\"total number of velocity samples : %d\" % count_sample_vel)\n",
    "\n",
    "                self.lastSample = bb\n",
    "                return bb\n",
    "\n",
    "\n",
    "def tmg(n, mu, M, initial, f=None, g=None, burn_in=30, verbose=False):\n",
    "    \"\"\"\n",
    "    This function generates samples from a Markov chain whose equilibrium distribution is a d-dimensional\n",
    "    multivariate Gaussian truncated by linear inequalities. The log probability density is\n",
    "    log p(X) = -0.5 (X-mu)^T M^-1 (X-mu) + const\n",
    "    in terms of a covariance matrix M and a mean vector mu. The constraints are imposed as explained below.\n",
    "    The Markov chain is built using the Hamiltonian Monte Carlo technique.\n",
    "\n",
    "    :param n:       Number of samples.\n",
    "    :param mu:      (m,) vector for the mean of multivariate Gaussian density\n",
    "    :param M:       (m,m) covariance matrix of the multivariate Gaussian density\n",
    "    :param initial: (m,) vector with the initial value of the Markov chain. Must satisfy\n",
    "                    the truncation inequalities strictly.\n",
    "    :param f:       (q,m) matrix, where q is the number of linear constraints. The constraints require each component\n",
    "                    of the m-dimensional vector fX+g to be non-negative\n",
    "    :param g:       (q,) vector with the constant terms in the above linear constraints.\n",
    "    :param burn_in: The number of burn-in iterations. The Markov chain is sampled n + burn_in\n",
    "                    times, and the last n samples are returned.\n",
    "    :param verbose:\n",
    "    :return: (n, m)\n",
    "    \"\"\"\n",
    "\n",
    "    dim = len(mu)\n",
    "    if M.shape[1] != dim:\n",
    "        raise ValueError(\"The covariance matrix must be square.\")\n",
    "\n",
    "    if len(initial) != dim:\n",
    "        raise ValueError(\"Wrong length for initial value vector.\")\n",
    "\n",
    "    # verify that M is positive definite, it will raise an error if M is not SPD\n",
    "    R = np.linalg.cholesky(M)\n",
    "\n",
    "    # we change variable to the canonical frame, and transform back after sampling\n",
    "    # X ~ N(mu, M), then R^-1(X-mu) ~ N(0, I)\n",
    "    init_trans = scipy.linalg.solve(R, initial - mu)  # the new initial value\n",
    "\n",
    "    if f is not None:\n",
    "        if f.shape[0] != len(g) or f.shape[1] != dim:\n",
    "            raise ValueError(\"Inconsistent linear constraints. f must \\\n",
    "                              be an d-by-m matrix and g an d-dimensional vector.\")\n",
    "        # g may contains infinity, extract valid constraints\n",
    "        valid = np.logical_and(g < np.inf, g > -np.inf)\n",
    "        g = g[valid]\n",
    "        f = f[valid]\n",
    "\n",
    "        # verify initial value satisfies linear constraints\n",
    "        if np.any(f@initial+g < 0):\n",
    "            raise ValueError(\"Initial point violates linear constraints.\")\n",
    "\n",
    "        # map linear constraints to canonical frame\n",
    "        f_trans = f@R\n",
    "        g_trans = f@mu+g\n",
    "\n",
    "        hmc = HmcSampler(dim, init_trans, f_trans, g_trans, verbose=verbose)\n",
    "    else:\n",
    "        hmc = HmcSampler(dim, init_trans, f, g, verbose=verbose)\n",
    "\n",
    "    samples = np.zeros((n, dim))\n",
    "    for i in range(burn_in):\n",
    "        if verbose:\n",
    "            print(\"=\"*30 + \" (burn in) sample {} \".format(i) + \"=\"*30)\n",
    "        hmc.sampleNext()\n",
    "    for i in range(n):\n",
    "        if verbose:\n",
    "            print(\"=\" * 30 + \" sample {} \".format(i) + \"=\" * 30)\n",
    "        samples[i] = hmc.sampleNext()\n",
    "\n",
    "    # transform back\n",
    "    return samples @ R.T + mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConstrainedGP:\n",
    "    \"\"\"\n",
    "    class attribute:\n",
    "    variable object:\n",
    "        dim:         1 or 2, indicates the dimension of underlying problem\n",
    "        interval:    1D-(2,) or 2D-(2,2), the input space\n",
    "        m:           scale or (2,), the number of basis functions (in each dimension)\n",
    "        constraints: a dictionary specify the the constraints imposed to the GP, it has three keys\n",
    "                     'increasing': True or False,\n",
    "                     'bounded': [] or (2,) indicating the range of the GP\n",
    "                     'convex': True or False\n",
    "        alpha:       scale, default to be 0.0000001, coefficient of diagonal shift to ensure numerical stability.\n",
    "        basis:       string, specify the basis function, now only spikes (hat functions) are supported.\n",
    "        samples:     (n,m), drawing from truncated multivariate Gaussian(tmg) after feeding the training data.\n",
    "        predict:     predicted value computed by samples\n",
    "\n",
    "    function object:\n",
    "        k(x,y):                       the covariance(kernel) function, now only SE covariance is used,\n",
    "                                      in the future can try other functions\n",
    "        inequality_constraints():     generate the l, Lambda, u which define the inequality constraints\n",
    "                                      l <= Lambda*xi <= u\n",
    "        basis_fun(x, j, which_dim=0): return the value of j-th basis function at dimension which_dim\n",
    "        interpolation_constraints(x): return the matrix Phi which defines the equality constraints phi* x = y\n",
    "        covariance():                 return the covariance function\n",
    "        mode(x, y):                   return the mean, covariance matrix of posterior distribution with equality\n",
    "                                      constraints only, and return the mode of tmg.\n",
    "        interpolate(xi, x):           return the value of interpolation function at x.\n",
    "        fit_gp(x, y, n, burn_in, method): return the samples of tmg generated by MCMC method\n",
    "        mean(x_test):                 return the mean of tmg at test data\n",
    "        var():                        return the variance of tmg at test data, must be called after mean(x_test)\n",
    "        confidence_interval(confidence):\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, m, constraints=None, interval=None, alpha=0.0000001, basis=\"spikes\"):\n",
    "        \"\"\"\n",
    "        :param m: scale or (2,), number of nodes in each dimension,\n",
    "                  if interval=[a,b], then t_j=(j-1)*(b-a)/(m-1), j=1,2,...,m\n",
    "        :param constraints: dictionary, its keys are\n",
    "                            increasing : boolean, true or false\n",
    "                            bounded    : empty or (2,) indicates the bound\n",
    "                            convex     : boolean, true or false\n",
    "        :param interval: (2,) or a list contains two intervals\n",
    "        :param alpha: for a matrix A with large condition number,\n",
    "                      let A = A + alpha * I to make A more stable in numerical computational\n",
    "        :param basis: types of basis function, e.g. \"spikes\"\n",
    "        \"\"\"\n",
    "        if constraints is None:\n",
    "            constraints = {'increasing': False, 'bounded': [], 'convex': False}\n",
    "        try:\n",
    "            dim = len(m)\n",
    "        except:\n",
    "            dim = 1\n",
    "        assert dim == 1 or dim == 2, \"Only support 1D and 2D case\"\n",
    "\n",
    "        if interval is None:\n",
    "            if dim == 1:\n",
    "                interval = [0, 1]\n",
    "            else:\n",
    "                interval = [[0, 1], [0, 1]]\n",
    "\n",
    "        self.dim = dim\n",
    "        self.interval = interval\n",
    "        self.m = m\n",
    "        self.constraints = constraints\n",
    "        self.alpha = alpha\n",
    "        self.basis = basis\n",
    "        self.samples = None\n",
    "        self.predict = None\n",
    "\n",
    "    def k(self, x, y):\n",
    "        \"\"\"\n",
    "        The covariance function. SE covariance function is used.\n",
    "        :param x: scale or (2,)\n",
    "        :param y: scale or (2,)\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        if self.dim == 1:\n",
    "            alpha = 0.2\n",
    "            sigma = 1\n",
    "            res = sigma ** 2 * math.exp(-(x - y) ** 2 / (2 * alpha ** 2))\n",
    "        else:\n",
    "            alpha1 = 0.2\n",
    "            alpha2 = 0.2\n",
    "            sigma = 1\n",
    "            res = sigma ** 2 * math.exp(-(x[0]-y[0])**2/(2*alpha1**2) -\n",
    "                                         (x[1]-y[1])**2/(2*alpha2**2))\n",
    "        return res\n",
    "\n",
    "    def inequality_constraints(self):\n",
    "        \"\"\"\n",
    "        Return the l, Lambda, u in the inequality conditions l <= Lambda* xi  <= u\n",
    "\n",
    "        :return:\n",
    "            l      : (q,1)\n",
    "            Lambda : (q,m) or (q, m1*m2)\n",
    "            u      : (q,1)\n",
    "            There are q linear inequalities of the form\n",
    "            l_k <= sum Lambda_kj*cj <= uk\n",
    "        \"\"\"\n",
    "        m = self.m\n",
    "        constraints = self.constraints\n",
    "        increasing = constraints['increasing']\n",
    "        convex = constraints['convex']\n",
    "        bounded = len(constraints['bounded']) > 0\n",
    "\n",
    "        if self.dim == 2 and (convex or (increasing and bounded)):\n",
    "            raise ValueError(\"In 2 dimension, only monotonicity or boundedness constraint is possible.\")\n",
    "\n",
    "        l = None\n",
    "        Lambda = None\n",
    "        u = None\n",
    "        if increasing and not bounded and not convex:\n",
    "            if self.dim == 1:\n",
    "                l = np.full(m, -np.inf)\n",
    "\n",
    "                u = np.zeros(m)\n",
    "                u[m - 1] = np.inf\n",
    "\n",
    "                Lambda = np.identity(m) + np.diag(np.full(m - 1, -1), 1)\n",
    "            else:\n",
    "                m1 = m[0]\n",
    "                m2 = m[1]\n",
    "                total_con = m2*(m1-1) + m1*(m2-1) + 1\n",
    "                l = np.full(total_con, -np.inf)\n",
    "                u = np.zeros(total_con)\n",
    "                u[-1] = np.inf\n",
    "\n",
    "                Lambda = []\n",
    "                for i in range(m1):\n",
    "                    for j in range(m2-1):\n",
    "                        tmp = np.zeros(m1*m2)\n",
    "                        tmp[i*m2+j] = 1\n",
    "                        tmp[i*m2+j+1] = -1\n",
    "                        Lambda.append(tmp)\n",
    "                for j in range(m2):\n",
    "                    for i in range(m1-1):\n",
    "                        tmp = np.zeros(m1*m2)\n",
    "                        tmp[i*m2+j] = 1\n",
    "                        tmp[(i+1)*m2+j] = -1\n",
    "                        Lambda.append(tmp)\n",
    "                tmp = np.zeros(m1*m2)\n",
    "                tmp[m1-1] = 1\n",
    "                Lambda.append(tmp)\n",
    "                Lambda = np.array(Lambda)\n",
    "\n",
    "        elif not increasing and bounded and not convex:\n",
    "            if self.dim == 2:\n",
    "                m = m[0]*m[1]\n",
    "            l = np.full(m, constraints['bounded'][0])\n",
    "\n",
    "            u = np.full(m, constraints['bounded'][1])\n",
    "\n",
    "            Lambda = np.identity(m)\n",
    "\n",
    "        elif not increasing and bounded and convex:\n",
    "            l = np.zeros(m)\n",
    "            l[0] = -np.inf\n",
    "            l[m - 1] = -np.inf\n",
    "\n",
    "            u = np.full(m, np.inf)\n",
    "\n",
    "            Lambda = np.identity(m) + np.diag(np.full(m - 1, 1), 1) + np.diag(np.full(m - 1, 1), -1)\n",
    "            Lambda[0, 1] = 0\n",
    "            Lambda[m - 1, m - 2] = 0\n",
    "            for i in range(1, m - 1):\n",
    "                Lambda[i, i] = -2\n",
    "\n",
    "        elif increasing and bounded and not convex:\n",
    "            l = np.full(m + 1, -np.inf)\n",
    "            l[0] = constraints['bounded'][0]\n",
    "\n",
    "            u = np.zeros(m + 1)\n",
    "            u[0] = np.inf\n",
    "            u[m] = constraints['bounded'][1]\n",
    "\n",
    "            Lambda = -np.identity(m) + np.diag(np.ones(m - 1), -1)\n",
    "            Lambda[0, 0] = 1\n",
    "            Lambda = np.vstack((Lambda, np.zeros(m)))\n",
    "            Lambda[m, m - 1] = 1\n",
    "\n",
    "        elif increasing and not bounded and convex:\n",
    "            l = np.zeros(m)\n",
    "            l[m - 1] = -np.inf\n",
    "\n",
    "            u = np.full(m, np.inf)\n",
    "\n",
    "            Lambda = np.identity(m) + np.diag(np.full(m - 1, 1), 1) + np.diag(np.full(m - 1, 1), -1)\n",
    "            Lambda[m - 1, m - 2] = 0\n",
    "            Lambda[0, 0] = -1\n",
    "            for i in range(1, m - 1):\n",
    "                Lambda[i, i] = -2\n",
    "\n",
    "        elif not increasing and bounded and convex:\n",
    "            Lambda1 = np.identity(m)\n",
    "            l1 = np.full(m, constraints['bounded'][0])\n",
    "            u1 = np.full(m, constraints['bounded'][1])\n",
    "\n",
    "            Lambda2 = np.zeros((m - 2, m))\n",
    "            for i in range(m - 2):\n",
    "                Lambda2[i, i:i + 3] = np.array([1, -2, 1])\n",
    "            l2 = np.zeros(m - 2)\n",
    "\n",
    "            u2 = np.full(m - 2, np.inf)\n",
    "\n",
    "            Lambda = np.vstack((Lambda1, Lambda2))\n",
    "            l = np.concatenate((l1, l2), axis=None)\n",
    "            u = np.concatenate((u1, u2), axis=None)\n",
    "\n",
    "        elif increasing and bounded and convex:\n",
    "            Lambda = np.zeros((m + 1, m))\n",
    "            for i in range(m - 2):\n",
    "                Lambda[i, i:i + 3] = np.array([1, -2, 1])\n",
    "            Lambda[m - 2, 0] = -1\n",
    "            Lambda[m - 2, 1] = 1\n",
    "            Lambda[m - 1, 0] = 1\n",
    "            Lambda[m, m - 1] = 1\n",
    "\n",
    "            l = np.zeros(m + 1)\n",
    "            l[m - 1] = constraints['bounded'][0]\n",
    "            l[m] = -np.inf\n",
    "\n",
    "            u = np.full(m + 1, np.inf)\n",
    "            u[m] = constraints['bounded'][1]\n",
    "        else:\n",
    "            pass\n",
    "        return l, Lambda, u\n",
    "\n",
    "    def basis_fun(self, x, j, which_dim=0):\n",
    "        \"\"\"\n",
    "        Return the value of basis function \\phi_j(x)\n",
    "\n",
    "        :param x:         scale, need to be in the interval\n",
    "        :param j:         integer, index of hat functions, 1 <= j <= m\n",
    "        :param which_dim: 0 or 1, specify which dimension in 2D case.\n",
    "                          0 for the first dimension, 1 for the second dimension\n",
    "\n",
    "        :return: \\phi_j(x)\n",
    "        \"\"\"\n",
    "        if self.dim == 1:\n",
    "            a = self.interval[0]  # lower bound\n",
    "            b = self.interval[1]  # upper bound\n",
    "            m = self.m\n",
    "        else:\n",
    "            a = self.interval[which_dim][0]\n",
    "            b = self.interval[which_dim][1]\n",
    "            m = self.m[which_dim]\n",
    "\n",
    "        assert np.all(np.logical_and(a <= x, x <= b)), 'x must be in the range of input interval'\n",
    "        dm = (b - a) / (m - 1)\n",
    "        tj = a + (j - 1) * dm\n",
    "        res = 1 - np.abs((x - tj) / dm)\n",
    "        res = np.array(res)\n",
    "        res[res < 0] = 0\n",
    "        return res\n",
    "\n",
    "    def interpolation_constraints(self, x):\n",
    "        \"\"\"\n",
    "        Return coefficient matrix in the Interpolation conditions\n",
    "\n",
    "        :param x: (n,) or (n,2), the design of experiment [x1,x2,...,xn]\n",
    "        :return: 1D: (n,m), with entry phi_j(xi)\n",
    "                 2D: (n, m1*m2)\n",
    "        \"\"\"\n",
    "        if self.dim == 1:\n",
    "            return np.array([self.basis_fun(x, j) for j in range(1, self.m + 1)]).T\n",
    "        else:\n",
    "            n = len(x)\n",
    "            phi_1 = np.array([self.basis_fun(x[:, 0], j) for j in range(1, self.m[0] + 1)]).T\n",
    "            phi_2 = np.array([self.basis_fun(x[:, 1], j) for j in range(1, self.m[1] + 1)]).T\n",
    "            res = [np.kron(phi_1[i], phi_2[i]) for i in range(n)]\n",
    "            res = np.array(res)\n",
    "            return res\n",
    "\n",
    "    def covariance(self):\n",
    "        \"\"\"\n",
    "        :return: (m,m), the covariance matrix (k(t_i,t_j)),\n",
    "                        t_j = a + j*(b-a)/(m-1), j=0,1,...,m-1. or\n",
    "                 (m1*m2, m1*m2),\n",
    "        \"\"\"\n",
    "        if self.dim == 1:\n",
    "            def t(j):\n",
    "                return self.interval[0] + j * (self.interval[1] - self.interval[0]) / (self.m - 1)\n",
    "\n",
    "            Gamma = [[self.k(t(i), t(j)) for j in range(self.m)] for i in range(self.m)]\n",
    "        else:\n",
    "            m1 = self.m[0]\n",
    "            m2 = self.m[1]\n",
    "            a1 = self.interval[0][0]\n",
    "            a2 = self.interval[1][0]\n",
    "            dm1 = (self.interval[0][1] - self.interval[0][0]) / (m1 - 1)\n",
    "            dm2 = (self.interval[1][1] - self.interval[1][0]) / (m2 - 1)\n",
    "\n",
    "            def t(k):\n",
    "                i = k / m2\n",
    "                j = k % m2\n",
    "                return [a1 + i*dm1, a2 + j*dm2]\n",
    "            Gamma = [[self.k(t(i), t(j)) for j in range(m1*m2)] for i in range(m1*m2)]\n",
    "        return np.array(Gamma)\n",
    "\n",
    "    def mode(self, x, y):\n",
    "        \"\"\"\n",
    "        :param x:     (n,) or (n,2), the design of experiment [x1,x2,...,xn]\n",
    "        :param y:     (n,), array_like, the true value at x\n",
    "\n",
    "        :return : (in 2D, m = m1*m2)\n",
    "        mu:    (m,) the posterior mean with interpolation condition only, Gamma*Phi^T*[Phi*Gamma*Phi^T]^-1*y\n",
    "        Sigma: (m,m), the covariance matrix of the posterior with interpolation condition only,\n",
    "                      Sigma = Gamma-Gamma*Phi^T*[Phi*Gamma*Phi^T]^-1*Phi*Gamma\n",
    "        mode:  (m,) the posterior mode which is given by the maximum of the PDF of the posterior\n",
    "        \"\"\"\n",
    "        l, Lambda, u = self.inequality_constraints()\n",
    "        Phi = self.interpolation_constraints(x)\n",
    "        Gamma = self.covariance()\n",
    "        Gamma = Gamma + self.alpha * np.eye(len(Gamma))\n",
    "        mu = Gamma@Phi.T@np.linalg.solve(Phi@Gamma@Phi.T, y)\n",
    "        Sigma = Gamma - Gamma@Phi.T@np.linalg.solve(Phi@Gamma@Phi.T, Phi)@Gamma\n",
    "        Sigma = Sigma + self.alpha * np.eye(len(Sigma))\n",
    "\n",
    "        if Lambda is None:\n",
    "            # no inequality constraints, so mode is the posterior mean\n",
    "            mode = mu\n",
    "        else:\n",
    "            xi = cp.Variable(np.prod(self.m))\n",
    "            obj = cp.Minimize(cp.matrix_frac(xi, Gamma))\n",
    "            constraints = [Phi @ xi == y]\n",
    "            if not np.all(l == -np.inf):\n",
    "                constraints.append(Lambda[l != -np.inf] @ xi >= l[l != -np.inf])\n",
    "            if not np.all(u == np.inf):\n",
    "                constraints.append(Lambda[u != np.inf] @ xi <= u[u != np.inf])\n",
    "\n",
    "            prob = cp.Problem(obj, constraints)\n",
    "            prob.solve()\n",
    "            if prob.status != \"optimal\":\n",
    "                raise ValueError('cannot compute the mode')\n",
    "            mode = xi.value\n",
    "\n",
    "        return mu, Sigma, mode\n",
    "\n",
    "    def interpolate(self, xi, x):\n",
    "        \"\"\"\n",
    "        :param x: scale or (2,)\n",
    "        :param xi: (m,) or (m1*m2,), the coefficients of basis function\n",
    "\n",
    "        :return: the value of interpolation function at x,\n",
    "                 function f = sum xi_j * phi_j(x)  (1D) or\n",
    "                 f = sum xi_kl * phi^1_k(x[1]) * phi^2_l(x[2])\n",
    "        \"\"\"\n",
    "        if self.dim == 1:\n",
    "            phi = [self.basis_fun(x, i + 1) for i in range(self.m)]\n",
    "            return np.array(phi).dot(xi)\n",
    "        else:\n",
    "            phi_1 = np.array([self.basis_fun(x[0], j, 0) for j in range(self.m[0])])\n",
    "            phi_2 = np.array([self.basis_fun(x[1], j, 1) for j in range(self.m[1])])\n",
    "            return np.kron(phi_1, phi_2).dot(xi)\n",
    "\n",
    "    def fit_gp(self, x, y, n=500, burn_in=100, method='HMC'):\n",
    "        \"\"\"\n",
    "\n",
    "        :param x: (n,) or (n, 2), the design of experiment [x1,x2,...,xn]\n",
    "        :param y: (n,)\n",
    "        :param n: Number of samples.\n",
    "        :param burn_in: The number of burn-in iterations in MCMC. The Markov chain is sampled n + burn_in\n",
    "                        times, and the last n samples are returned.\n",
    "        :param method:  sampling method. 'HMC' : Hamiltonian Monte Carlo. 'RSM' : reject sampling method.\n",
    "                        'Gibbs' : Gibbs sampling. 'MH' : Metropolis-Hastings\n",
    "        :return: (n, m) each row is a sample\n",
    "        \"\"\"\n",
    "        mu, Sigma, initial = self.mode(x, y)\n",
    "\n",
    "        l, Lambda, u = self.inequality_constraints()\n",
    "        if Lambda is not None:\n",
    "            # Lambda * xi - l >= 0\n",
    "            # -Lambda * xi + u >= 0\n",
    "\n",
    "            f = np.vstack((np.eye(len(l)), -np.eye(len(u))))\n",
    "            g = np.hstack((-l, u))\n",
    "\n",
    "            R = Lambda @ Sigma @ Lambda.T\n",
    "            R = R + self.alpha * np.eye(len(R))\n",
    "\n",
    "            eta = Lambda @ initial  # new initial value, constraints: eta >= l, eta <= u,\n",
    "            # however the constraints may not be satisfied due to numerical issue\n",
    "            eta[eta < l] = l[eta < l] + 1e-8\n",
    "            eta[eta > u] = u[eta > u] - 1e-8\n",
    "\n",
    "            if method == 'HMC':\n",
    "                samples = tmg(n, Lambda@mu, R, eta, f, g, burn_in=burn_in)\n",
    "            else:\n",
    "                raise ValueError(\"Not supported method.\")\n",
    "            samples = np.linalg.solve(Lambda.T@Lambda, Lambda.T)@samples.T\n",
    "            samples = samples.T\n",
    "        else:\n",
    "            # we have analytic formulation of the posterior distribution\n",
    "            if method == 'HMC':\n",
    "                samples = tmg(n, mu, Sigma, initial, None, None, burn_in=burn_in)\n",
    "            else:\n",
    "                raise ValueError(\"Not supported method.\")\n",
    "        self.samples = samples\n",
    "\n",
    "    def mean(self, x_test):\n",
    "        \"\"\"\n",
    "        the conditional mean at x_test\n",
    "        :param x_test: (k,) or (k, 2) k test points\n",
    "        \"\"\"\n",
    "        assert self.samples is not None, \"Has not fit yet.\"\n",
    "        if self.dim == 1:\n",
    "            coeff_phi = [self.basis_fun(x_test, j + 1) for j in range(self.m)]  # (m,k)\n",
    "            coeff_phi = np.array(coeff_phi).T  # (k, m)\n",
    "        else:\n",
    "            k = len(x_test)\n",
    "            phi_1 = np.array([self.basis_fun(x_test[:, 0], j) for j in range(1, self.m[0] + 1)]).T\n",
    "            phi_2 = np.array([self.basis_fun(x_test[:, 1], j) for j in range(1, self.m[1] + 1)]).T\n",
    "            coeff_phi = [np.kron(phi_1[i], phi_2[i]) for i in range(k)]\n",
    "            coeff_phi = np.array(coeff_phi)\n",
    "        self.predict = coeff_phi @ self.samples.T   #(k,n)\n",
    "        return np.mean(self.predict, axis=1)\n",
    "\n",
    "    def var(self):\n",
    "        \"\"\"\n",
    "        the conditional variance after computing mean for test data\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        if self.predict is not None:\n",
    "            return np.var(self.predict, axis=1)\n",
    "        else:\n",
    "            raise ValueError(\"mean() must be called first.\")\n",
    "\n",
    "    def confidence_interval(self, confidence=0.9):\n",
    "        assert self.predict is not None, \"Need to call mean() first.\"\n",
    "        n = self.predict.shape[0]\n",
    "        h = np.sqrt(self.var()) * scipy.stats.t.ppf((1 + confidence) / 2., n - 1)\n",
    "        return np.mean(self.predict, axis=1) - h, np.mean(self.predict, axis=1) + h\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAAeZElEQVR4nO3deXxU9b3/8dcnM1kIOyRhR3YBWQQjaLWKuFxcaetSaXErgrUuv1+tXvXaq7229/Zaf/b+qnUt4gI/F6S1UqVSq7ihLEEkCCKGsIU1LEZISDLL9/dHBgwxkAFm5mRm3s/HI4+ZOeebzPuQyfvx5cycc8w5h4iIJL8MrwOIiEhsqNBFRFKECl1EJEWo0EVEUoQKXUQkRfi9euK8vDzXq1cvr55eRCQpLVmyZIdzLr+xdZ4Veq9evSgqKvLq6UVEkpKZrT/UOu1yERFJESp0EZEUoUIXEUkRTRa6mU0zs+1m9tkh1puZPWxmJWZWbGYjYx9TRESaEs0M/Vlg3GHWnw/0j3xNAR4/9lgiInKkmix059z7wK7DDBkPPO/qLADamVmXWAUUEZHoxGIfejdgY73HZZFl32JmU8ysyMyKysvLY/DUIiKyX0I/h+6cewp4CqCwsFDn7RWRpOOcIxh21ATDVAdC1ATD1ERuDzxuYt3ZAwsY3qNdzLPFotA3AT3qPe4eWSYiklC1wTBVtUEqa0NU1URua4NU1YSorA1SVRuisiZ4UMFWB0KRrzA1wbrb6gYl3HBs+BinowWts5ttoc8Gbjazl4DRQIVzbksMfq6IpKhgKExVIMS+SMFW1butqo2Ub/1Crg19q5T3Bb79vcEjbNqczAxyMn3k+H1kZ2aQ4/eRk5lBdqaP1jl+8ltnk5PpI9ufUTf2oHF197P9GWTv/z5/3djset+T7d8/LrLOn4GZxeXftclCN7MXgTFAnpmVAfcBmQDOuSeAOcAFQAlQBVwXl6QikrSqAyHeX13OG8u3MG/Vdr6uDkb9vRkGLbP95Gb5aJnlp0WWj5bZfjq0zKJH+9y65ZH1dV9+WmZ/c9si8+DHuZl+crIyyPLFr1i90mShO+cmNLHeATfFLJGIpISaYIgPv9zB68VbeGvlNvbWBGmfm8m4IZ3pHini+uW7v5C/Kee623jOaFONZyfnEpHUUxsMM3/NDl5ftoV/rNzKnuogbVtkcsHQzlw0rCun9u1Ipk8HqMeLCl1EjkkgFOajNTt5o3gzc1dso2JfgNY5fs4b3JmLhnfhtL55ZPlV4omgQheRIxYMhVlQuos3lm/mzc+2srsqQKtsP+cO7sRFw7pwev88sv0+r2OmHRW6iEStsibI795cxevFW9hZWUtulo9zBtWV+BkD8snJVIl7SYUuIlGpDoSY/HwRC9fuYtyQzlw8rAtjji9QiTcjKnQRaVIgFOaWF5fy0Zqd/P6K4fxgZHevI0kj9E6FiBxWOOz411nFvLVyG/ePP0Fl3oyp0EXkkJxz3Dd7Ba8u3cQd/3I8V5/ay+tIchgqdBE5pAfnfsH0Beu54Yw+/GxMX6/jSBNU6CLSqMffXcNj765hwqie3HX+QB2tmQRU6CLyLTMWrOeBN1dx8fCu/OZ7Q1TmSUKFLiIHee3TTfz7a58xdmABv79iOL4MlXmyUKGLyAH/XLmN22YuY3TvDjz245E670qS0W9LRAD4aM0OfvbCJwzp2oap15ysA4aSkApdRFi6YTeTnyuiV8dcnr1uFK2ydcxhMlKhi6S5L7bu4dpnFtOxVTbTJ42mfcssryPJUVKhi6SxdTsqmfj0QnIyM5gxaTSd2uR4HUmOgQpdJE1tqdjHj6cuJBgKM2PSaHp2zPU6khwj7SgTSUM799YwcepCKvYFeHHyKfTv1NrrSBIDmqGLpJmvqwNc88wiynbv4+lrChnava3XkSRGVOgiaWRfbYhJzy5m1ZY9PDHxJEb36eh1JIkh7XIRSRO1wTA/nbGEovW7eWTCCM4aWOB1JIkxzdBF0kAo7Pj5y5/y3upyfvv9oVw0rKvXkSQOVOgiKc45x7/9ZTlvLN/CLy8cxJWjenodSeJEhS6Swpxz/OaNz3m5aCO3ju3H9d/t43UkiSMVukgKe/jtEp7+cC3XfqcXPz93gNdxJM5U6CIpatqHa/mff67m0pHdufeiwTqneRpQoYukoFeKNnL/6ysZd0JnHrh0KBk6p3laUKGLpJi/L9/CnX8u5rv98/jDhBPx65zmaUO/aZEU8t7qcm59aSkjerbnyatOItuvc5qnExW6SIpYvG4XN0wvon9Ba6ZdezK5WTpuMN1EVehmNs7MvjCzEjO7q5H1Pc1snpktNbNiM7sg9lFF5FA+21TBT55ZTNe2LXh+0ijatsj0OpJ4oMlCNzMf8ChwPjAYmGBmgxsM+yUw0zk3ArgSeCzWQUWkcSXb93L1tEW0aZHJjOtHk9cq2+tI4pFoZuijgBLnXKlzrhZ4CRjfYIwD2kTutwU2xy6iiBxK2e4qrnp6IRkG0yeNomu7Fl5HEg9FU+jdgI31HpdFltX3K2CimZUBc4BbGvtBZjbFzIrMrKi8vPwo4orIftv3VDNx6kIqa4JMnzSaPvmtvI4kHovVm6ITgGedc92BC4DpZvatn+2ce8o5V+icK8zPz4/RU4ukn4qqAFc/vYhtX9fwzHWjGNSlTdPfJCkvmkLfBPSo97h7ZFl9k4CZAM65j4EcIC8WAUXkYJU1Qa59dhGl5ZX86epCTjquvdeRpJmIptAXA/3NrLeZZVH3pufsBmM2AGcDmNkg6gpd+1REYqwmGGLK9CKKyyp4eMIITu+veZN8o8lCd84FgZuBucDn1H2aZYWZ3W9ml0SG/QKYbGbLgBeBa51zLl6hRdLVw29/yfySnTxw6TDGDensdRxpZqI68sA5N4e6NzvrL7u33v2VwGmxjSYi9X268Ssef3cNVxR257KTunsdR5ohHSkqkgSqAyF+MfNTOrfJ4ZcXNTwMRKSOjg0WSQL/89Zq1pRXMn3SKNrk6ChQaZxm6CLN3JL1u3jqg1J+NLon3+2vj/vKoanQRZqxfbUhbn+lmG7tWvBvFwzyOo40c9rlItKMPTj3C9buqOSFyaNpla0/Vzk8zdBFmqmFpTt55qO1XHPqcXynrz5vLk1ToYs0Q5U1Qe6YVUyP9rncef5Ar+NIktD/4USaoQfeXMXG3VW8POVUXahCoqYZukgzM79kB89/vJ6fnNabUb07eB1HkogKXaQZ2VMd4F9nFdMnryW3n3e813Ekyej/ciLNyH/NWcWWin288tPv0CJLF3iWI6MZukgz8d7qcl5ctIHJZ/TRKXHlqKjQRZqBin0B7pxVTL+CVvz8nAFex5EkpUIXaQZ+8/pKyvfW8NDlw8nJ1K4WOToqdBGPvf35Nl5ZUsaNZ/ZleI92XseRJKZCF/HQV1W13P2X5Qzs3Jpbzu7ndRxJcvqUi4iH/uNvK9lVWcu0a08m269dLXJsNEMX8cjcFVt5dekmbh7bjyHd2nodR1KACl3EA7sqa7nn1eUM7tKGm87SrhaJDe1yEfHAva99RsW+ADOuH02mT/MqiQ29kkQS7I3iLbxevIX/fc4ABnZu43UcSSEqdJEE2rm3hn9/7TOGdW/LDWf08TqOpBjtchFJoKc+KGV3VS0vTj4Fv3a1SIzpFSWSILsra5n+8XouHtaV4zu39jqOpCAVukiCTJu/lqraEDeP1adaJD5U6CIJULEvwLPz13H+kM4M6KTZucSHCl0kAZ6dv449NUHNziWuVOgicbanOsC0+Ws5Z1ABJ3TVEaESPyp0kTibvmA9FfsC3DK2v9dRJMWp0EXiqKo2yNQP1nLGgHydGlfiToUuEkcvLNzArspabtW+c0kAFbpInFQHQjz5fimn9ulIYa8OXseRNBBVoZvZODP7wsxKzOyuQ4y5wsxWmtkKM3shtjFFks/LizdSvqdGF66QhGny0H8z8wGPAucCZcBiM5vtnFtZb0x/4G7gNOfcbjMriFdgkWRQEwzxxHtrOLlXe07t09HrOJImopmhjwJKnHOlzrla4CVgfIMxk4FHnXO7AZxz22MbUyS5/HnJJrZUVHPL2P6YmddxJE1EU+jdgI31HpdFltU3ABhgZvPNbIGZjWvsB5nZFDMrMrOi8vLyo0ss0swFQmEee7eE4T3a8d3+eV7HkTQSqzdF/UB/YAwwAfiTmbVrOMg595RzrtA5V5ifnx+jpxZpXl5duomy3fu4dWw/zc4loaIp9E1Aj3qPu0eW1VcGzHbOBZxza4HV1BW8SFoJhsI8Nq+EE7q2YexAvZUkiRVNoS8G+ptZbzPLAq4EZjcY81fqZueYWR51u2BKYxdTJDm8XryFdTuruEWzc/FAk4XunAsCNwNzgc+Bmc65FWZ2v5ldEhk2F9hpZiuBecAdzrmd8Qot0hyFw44/zivh+E6tOW9wZ6/jSBqK6opFzrk5wJwGy+6td98Bt0W+RNLS3z/bSsn2vTw8YQQZGZqdS+LpSFGRGAiHHY+88yV98lty4dAuXseRNKVCF4mBf36+jVVb93DTmH74NDsXj6jQRY6Rc45H3imhZ4dcxp/Y1es4ksZU6CLH6N3V5SzfVMFNZ/XF79OflHhHrz6RY+Cc45G3v6RbuxZ8f0R3r+NImlOhixyDj9bs5JMNX/HTMX3J8uvPSbylV6DIMXj47S/p1Caby0/S7Fy8p0IXOUoLS3eycO0ubjijLzmZPq/jiKjQRY7WI++UkNcqiwmjenodRQRQoYsclU827ObDkh1M/m4fWmRpdi7Ngwpd5Cg88vaXtM/NZOIpx3kdReQAFbrIEVpeVsG8L8qZdHpvWmZHdTokkYRQoYscoUfe+ZI2OX6u/k4vr6OIHESFLnIEVm39mn+s3MZ1p/WmTU6m13FEDqJCFzkCj7xTQqtsP9ed1svrKCLfokIXiVLJ9j3MWb6Fq089jna5WV7HEfkWFbpIlB6dt4Ycv49Jp/f2OopIo1ToIlFYu6OS1z7dxMRTetKxVbbXcUQapUIXicJj80rI9GUw+Yw+XkcROSQVukgTNu6q4tWlm5gwqicFrXO8jiNySCp0kSY8/t4aMsy44UzNzqV5U6GLHMaWin3MKirjssLudGnbwus4IoelQhc5jCffKyXsHDee2dfrKCJNUqGLHML2PdW8uGgDPxjZjR4dcr2OI9IkFbrIIfzp/VICoTA/G9PP6ygiUVGhizRi594aZizYwPgTu9Err6XXcUSiokIXacTUD9dSHQxx01manUvyUKGLNPBVVS3Pf7SOC4Z2oV9BK6/jiERNhS7SwLT566isDXHLWM3OJbmo0EXq+bo6wDPz13Le4E4M7NzG6zgiR0SFLlLP8x+tY091kFvG9vc6isgRi6rQzWycmX1hZiVmdtdhxl1qZs7MCmMXUSQxKmuCPP3hWs46Pp+h3dt6HUfkiDVZ6GbmAx4FzgcGAxPMbHAj41oD/wtYGOuQIokwY8F6dlcFuOVszc4lOUUzQx8FlDjnSp1ztcBLwPhGxv0aeACojmE+kYTYVxviTx+U8t3+eYzs2d7rOCJHJZpC7wZsrPe4LLLsADMbCfRwzr1xuB9kZlPMrMjMisrLy484rEi8vLBoAzv21mrfuSS1Y35T1MwygN8Dv2hqrHPuKedcoXOuMD8//1ifWiQmqgMhnnxvDaN7d2BU7w5exxE5atEU+iagR73H3SPL9msNDAHeNbN1wCnAbL0xKsnilaKNbN9Tw63ady5JLppCXwz0N7PeZpYFXAnM3r/SOVfhnMtzzvVyzvUCFgCXOOeK4pJYJIZqg2Eef3cNI3u24zt9O3odR+SYNFnozrkgcDMwF/gcmOmcW2Fm95vZJfEOKBJPf/mkjM0V1dxydn/MzOs4IsfEH80g59wcYE6DZfceYuyYY48lEn+BUJhH3y1hWPe2jBmg93Qk+elIUUlbr326mY279nHzWf00O5eUoEKXtBQKOx6bV8LAzq05d3Anr+OIxIQKXdLS68WbKd1Rya3ady4pRIUuaSccdjw6r4T+Ba0Yd0Jnr+OIxIwKXdLO3BVbWb1tLzeP7UdGhmbnkjpU6JJWnHM88k4JvfNactGwrl7HEYkpFbqkldnLNrNyy9f8bExffJqdS4pRoUva2L6nmvtmr2B4j3Z8f0S3pr9BJMmo0CUtOOe459XPqKoN8dDlw/H79NKX1KNXtaSFV5du4q2V27jjvOPpV9DK6zgicaFCl5S3taKaX81eQeFx7fnJ6b29jiMSNyp0SWnOOe7+SzG1oTAPXj5cb4RKSlOhS0p7ZUkZ874o585xA+md19LrOCJxpUKXlLX5q338+m8rGd27A9ec2svrOCJxp0KXlOSc484/FxNyjgcvG64jQiUtqNAlJb24aCMffLmDuy8YRM+OuV7HEUkIFbqknI27qvjPN1ZyWr+O/HhUT6/jiCSMCl1SSjjs+NdZxZgZD1w6TLtaJK2o0CWlzFi4no9Ld/LLCwfRvb12tUh6UaFLyli3o5LfzlnFmQPy+eHJPbyOI5JwKnRJCeGw445Zy/D7jP++dKiuQiRpSYUuKeGZj9axeN1u7rv4BLq0beF1HBFPqNAl6ZWW7+V3b67i7IEFXDpSp8WV9KVCl6QWCjtuf2UZOZk+fvsD7WqR9Ob3OoDIsZj6QSmfbPiKP1x5IgVtcryOI+IpzdAlaX25bQ8PvbWafzmhE5cM1/VBRVTokpSCoTC3v7KMllk+fvM97WoRAe1ykST15PulLCur4NEfjSS/dbbXcUSaBc3QJems2vo1//efq7lwWBcuHNbF6zgizYYKXZJKIBTmFzOX0bZFJr8eP8TrOCLNina5SNIIhx13zipmxeaveWLiSXRomeV1JJFmJaoZupmNM7MvzKzEzO5qZP1tZrbSzIrN7G0zOy72USWdOef4j7+t4C9LN3H7eQMYN6Sz15FEmp0mC93MfMCjwPnAYGCCmQ1uMGwpUOicGwbMAn4X66CS3h76x2qe+3g9U87ow01n9fM6jkizFM0MfRRQ4pwrdc7VAi8B4+sPcM7Nc85VRR4uALrHNqaksyffW8Mf55UwYVQP7j5/oD6iKHII0RR6N2BjvcdlkWWHMgn4e2MrzGyKmRWZWVF5eXn0KSVtvbBwA7/9+youGtZFnzcXaUJMP+ViZhOBQuDBxtY7555yzhU65wrz8/Nj+dSSgmYv28w9f13OWcfn8/srTsSnqw+JHFY0n3LZBNS/WkD3yLKDmNk5wD3Amc65mtjEk3T1zqpt3Pbyp5zcqwOPTzyJLL8+YSvSlGj+ShYD/c2st5llAVcCs+sPMLMRwJPAJc657bGPKenk4zU7uXHGJwzu2oanrykkJ9PndSSRpNBkoTvngsDNwFzgc2Cmc26Fmd1vZpdEhj0ItAJeMbNPzWz2IX6cyGEt2/gV1z+3mJ4dcnn2ulG0zsn0OpJI0ojqwCLn3BxgToNl99a7f06Mc0kaWr1tD9c8s4gOrbKYPmm0DhwSOULaMSnNwoadVUycupAsXwb/b9IpdG6rc5uLHCkd+i+e21pRzY+fXkBtKMzMG06lZ8dcryOJJCXN0MVTuypruerpheyuDPDcdaMY0Km115FEkpYKXTyzpzrANdMWsWFXFVOvKWR4j3ZeRxJJaip08UR1IMSk54r4fMvXPD5xJKf06eh1JJGkp33oknC1wTA3zljC4nW7+MOVIxg7sJPXkURSgmboklChsOO2mZ8y74ty/vN7Q3VxZ5EYUqFLwjjnuOfV5bxevIW7zx/Ij0b39DqSSEpRoUtCOOf4rzmf89Lijdx0Vl9uOLOv15FEUo4KXRLij++U8KcP1nLNqcdx+3nHex1HJCWp0CXunp2/lofeWs0PRnTjvotP0DnNReJEhS5x9eclZfzqbys5b3AnfnfZMDJ0TnORuFGhS9y8+dlW7pi1jNP75fHIj0bg9+nlJhJP+guTuPjgy3JufXEpJ/Zox5NXnUS2X+c0F4k3FbrE3JL1u5ny/BL65LfkmWtH0TJbx6+JJIIKXWJq5eavue6ZRXRqk830SaNpm6sLVIgkigpdYqa0fC9XT1tIq2w/M64fTX7rbK8jiaQVFbrExKav9jFx6kKcg+nXj6Z7e53TXCTRtHNTjln5nhqumrqQPTVBXppyCn3zW3kdSSQtaYYux6RiX4Crpy1iS0U1z1x7Mid0bet1JJG0pUKXo1ZVG+Qnzy5mzfa9PHnVSRT26uB1JJG0pkKXo1ITDHHD9CUs3bCbhyecyBkD8r2OJJL2tA9djlgwFObWF5fywZc7+D+XD2fckC5eRxIRNEOXIxQMhbnzz8uZu2Ib9108mMtO6u51JBGJ0AxdmhQMhVlQuos3lm9h7oqt7Kqs5bZzB3Ddab29jiYi9ajQpVHBUJiFa+tK/M3P6kq8ZZaPswd1YvyJXRk7sMDriCLSgApdDgiFHQtLdx4o8Z2VteRGSvzCoV0Yc3w+OZk6yZZIc6VCT3OhsGPh2p3MiZT4jr21tMj0cfagAi4a1oUzBxTQIkslLpIMVOhpKBR2LFq7izeWb+bNz7axY28NLTJ9jB1UwEVDuzDmeJW4SDJSoScB5xy1oTD7akNURb7q7gepCoQOLN9XG/xmfSCyvrb++hBVgSBbvqpmZ2UtOZkZnD2wExcM7cJZA/PJzdLLQSSZ6S/4GAVCYWqCYaoDochX3f2a4Df3D9zWW3agZAPflHB1oH5h1yvjQIhQ2B1Rrmx/BrlZPnKz/LTI8pGb5aNFpo/8VtkMKGjN2EEFjB1YoBIXSSFR/TWb2TjgD4APmOqc++8G67OB54GTgJ3AD51z62Ib9fBCYXegRL91GwhRHdxftN/c1jR4XB0IURMIR4q34bq6n1cTqFfewfARF+1+ZpCb6aNFlj9SvL4Dxds+N+tby3Kz/LTIrL/Mf/D6zIOLW9fuFEk/TRa6mfmAR4FzgTJgsZnNds6trDdsErDbOdfPzK4EHgB+GI/AMxdv5In311DToLgDoaMrVqgr1xy/j5zMDHIyfWT7v7nNzvTRKttPXquDl+dkRsb7fQfuZx+0zkdO/fuZGWQ3eA4zla6IxE40M/RRQIlzrhTAzF4CxgP1C3088KvI/VnAH83MnHNH37KH0L5lFoO6tCHH7yP7QKF+U5YHSrde2e4v5sYKOdvvI9NnKlcRSXrRFHo3YGO9x2XA6EONcc4FzawC6AjsqD/IzKYAUwB69ux5VIHPHdyJcwd3OqrvFRFJZQk9l4tz7innXKFzrjA/X2fnExGJpWgKfRPQo97j7pFljY4xMz/Qlro3R0VEJEGiKfTFQH8z621mWcCVwOwGY2YD10TuXwa8E4/95yIicmhN7kOP7BO/GZhL3ccWpznnVpjZ/UCRc2428DQw3cxKgF3Ulb6IiCRQVJ9Dd87NAeY0WHZvvfvVwOWxjSYiIkdCF7gQEUkRKnQRkRShQhcRSRHm1YdRzKwcWH+U355Hg4OW0oy2P723H/RvkM7bf5xzrtEDeTwr9GNhZkXOuUKvc3hF25/e2w/6N0j37T8U7XIREUkRKnQRkRSRrIX+lNcBPKbtl3T/N0j37W9UUu5DFxGRb0vWGbqIiDSgQhcRSRHNutDNbJyZfWFmJWZ2VyPrs83s5cj6hWbWy4OYcRPF9t9mZivNrNjM3jaz47zIGS9NbX+9cZeamTOzlPoYWzTbb2ZXRF4DK8zshURnjKcoXv89zWyemS2N/A1c4EXOZsU51yy/qDuz4xqgD5AFLAMGNxjzM+CJyP0rgZe9zp3g7T8LyI3cvzHdtj8yrjXwPrAAKPQ6d4J///2BpUD7yOMCr3MnePufAm6M3B8MrPM6t9dfzXmGfuBaps65WmD/tUzrGw88F7k/CzjbUufioE1uv3NunnOuKvJwAXUXH0kV0fz+AX5N3UXJqxMZLgGi2f7JwKPOud0AzrntCc4YT9FsvwPaRO63BTYnMF+z1JwLvbFrmXY71BjnXBDYfy3TVBDN9tc3Cfh7XBMlVpPbb2YjgR7OuTcSGSxBovn9DwAGmNl8M1tgZuMSli7+otn+XwETzayMutN735KYaM1XVOdDl+bNzCYChcCZXmdJFDPLAH4PXOtxFC/5qdvtMoa6/529b2ZDnXNfeRkqgSYAzzrnHjKzU6m7yM4Q51zY62Beac4z9HS/lmk024+ZnQPcA1zinKtJULZEaGr7WwNDgHfNbB1wCjA7hd4Yjeb3XwbMds4FnHNrgdXUFXwqiGb7JwEzAZxzHwM51J20K20150JP92uZNrn9ZjYCeJK6Mk+l/afQxPY75yqcc3nOuV7OuV7UvYdwiXOuyJu4MRfN6/+v1M3OMbM86nbBlCYwYzxFs/0bgLMBzGwQdYVentCUzUyzLfTIPvH91zL9HJjpItcyNbNLIsOeBjpGrmV6G3DIj7Ylmyi3/0GgFfCKmX1qZg1f8Ekryu1PWVFu/1xgp5mtBOYBdzjnUuJ/qFFu/y+AyWa2DHgRuDaFJnRHRYf+i4ikiGY7QxcRkSOjQhcRSREqdBGRFKFCFxFJESp0EZEUoUIXEUkRKnQRkRTx/wFtulOI1hBt8gAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "m = 8\n",
    "Gp = ConstrainedGP(m, constraints={'increasing': True, 'bounded': [0, 1], 'convex': False}, interval=[0, 1])\n",
    "\n",
    "# Training data\n",
    "x_train = np.array([0.25, 0.5, 0.75])\n",
    "y_train = np.array([0.02275013, 0.5, 0.97724987])\n",
    "\n",
    "Gp.fit_gp(x_train, y_train, n=20, burn_in=50, method='HMC')\n",
    "\n",
    "x_test = np.arange(0, 1, 0.05)\n",
    "y_pred = Gp.mean(x_test)\n",
    "\n",
    "plt.plot(x_test, y_pred)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "912d6611990680b3d240e982c9d50f3da4c776707cfd42695cf7d82c88d80956"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
